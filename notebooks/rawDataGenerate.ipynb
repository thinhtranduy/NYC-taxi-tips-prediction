{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook perform raw data transformation, and saved the processed data to `data/raw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"Duy Thinh raw data\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '4g')\n",
    "    .config('spark.executor.memory', '2g')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading schema and cast appropriate datatypes, convert all column names to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vendorid': IntegerType(),\n",
       " 'tpep_pickup_datetime': TimestampNTZType(),\n",
       " 'tpep_dropoff_datetime': TimestampNTZType(),\n",
       " 'passenger_count': LongType(),\n",
       " 'trip_distance': DoubleType(),\n",
       " 'ratecodeid': LongType(),\n",
       " 'store_and_fwd_flag': StringType(),\n",
       " 'pulocationid': IntegerType(),\n",
       " 'dolocationid': IntegerType(),\n",
       " 'payment_type': LongType(),\n",
       " 'fare_amount': DoubleType(),\n",
       " 'extra': DoubleType(),\n",
       " 'mta_tax': DoubleType(),\n",
       " 'tip_amount': DoubleType(),\n",
       " 'tolls_amount': DoubleType(),\n",
       " 'improvement_surcharge': DoubleType(),\n",
       " 'total_amount': DoubleType(),\n",
       " 'congestion_surcharge': DoubleType(),\n",
       " 'airport_fee': DoubleType()}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_all = spark.read.parquet('../data/landing/*')\n",
    "sdf_schema = sdf_all.schema\n",
    "schema_dict = {field.name.lower(): field.dataType for field in sdf_schema.fields}\n",
    "schema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18816606"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_all.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part implemented the logic described above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for month in range(7, 13):\n",
    "    input_path = f'../data/landing/2023-{str(month).zfill(2)}-yellow_cab.parquet'\n",
    "    output_path = f'../data/raw/2023-{str(month).zfill(2)}-yellow_cab'\n",
    "    \n",
    "    sdf_malformed = spark.read.parquet(input_path)\n",
    "    \n",
    "    # Convert column names to lowercase\n",
    "    consistent_col_casing_malformed = [F.col(col_name).alias(col_name.lower()) for col_name in sdf_malformed.columns]\n",
    "    sdf_malformed = sdf_malformed.select(*consistent_col_casing_malformed)\n",
    "    \n",
    "    # Cast columns to match the schema, only for columns present in the schema\n",
    "    casted_columns = [\n",
    "        F.col(c).cast(schema_dict[c]) \n",
    "        for c in sdf_malformed.columns \n",
    "        if c in schema_dict\n",
    "    ]\n",
    "    \n",
    "    # Ensure all columns are in the schema\n",
    "    for col_name in sdf_malformed.columns:\n",
    "        if col_name not in schema_dict:\n",
    "            raise ValueError(f\"Column '{col_name}' in the DataFrame is not present in the schema.\")\n",
    "\n",
    "    sdf_malformed = sdf_malformed.select(*casted_columns)\n",
    "    \n",
    "    sdf_malformed \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode('overwrite') \\\n",
    "    .parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "|       1| 2023-07-01 00:29:59|  2023-07-01 00:40:15|              1|          1.8|         1|                 N|         140|         263|           1|       12.1|  3.5|    0.5|       5.1|         0.0|                  1.0|        22.2|                 2.5|        0.0|\n",
      "|       2| 2023-07-01 00:03:25|  2023-07-01 00:23:44|              1|         2.31|         1|                 N|         163|         163|           2|       19.1|  1.0|    0.5|       0.0|         0.0|                  1.0|        24.1|                 2.5|        0.0|\n",
      "|       2| 2023-07-01 00:38:29|  2023-07-01 00:48:53|              1|         2.36|         1|                 N|         142|         262|           1|       13.5|  1.0|    0.5|       3.7|         0.0|                  1.0|        22.2|                 2.5|        0.0|\n",
      "|       2| 2023-07-01 00:14:16|  2023-07-01 00:29:13|              1|         4.36|         1|                 N|          68|          24|           1|       19.8|  1.0|    0.5|      4.96|         0.0|                  1.0|       29.76|                 2.5|        0.0|\n",
      "|       1| 2023-07-01 00:11:15|  2023-07-01 00:20:47|              0|          1.6|         1|                 N|         161|         107|           1|       11.4|  3.5|    0.5|      3.25|         0.0|                  1.0|       19.65|                 2.5|        0.0|\n",
      "|       2| 2023-07-01 00:29:32|  2023-07-01 00:54:14|              1|         8.67|         1|                 N|         138|         186|           1|       38.7|  6.0|    0.5|       7.0|        6.55|                  1.0|        64.0|                 2.5|       1.75|\n",
      "|       2| 2023-07-01 00:24:43|  2023-07-01 00:47:49|              1|         9.11|         1|                 N|         138|         230|           1|       39.4|  6.0|    0.5|     11.19|        6.55|                  1.0|       68.89|                 2.5|       1.75|\n",
      "|       2| 2023-07-01 00:35:28|  2023-07-01 00:45:30|              1|         3.08|         1|                 N|         166|         244|           1|       14.9|  1.0|    0.5|      3.48|         0.0|                  1.0|       20.88|                 0.0|        0.0|\n",
      "|       1| 2023-07-01 00:31:05|  2023-07-01 00:35:20|              0|          1.1|         1|                 N|         138|          70|           1|        7.9| 7.75|    0.5|       3.4|         0.0|                  1.0|       20.55|                 0.0|       1.75|\n",
      "|       2| 2023-07-01 00:38:00|  2023-07-01 00:54:47|              3|         3.88|         1|                 N|         186|          24|           1|       19.8|  1.0|    0.5|       1.0|         0.0|                  1.0|        25.8|                 2.5|        0.0|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sdf = spark.read.parquet('../data/raw/*')\n",
    "raw_sdf.show(10, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendorid: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- ratecodeid: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pulocationid: integer (nullable = true)\n",
      " |-- dolocationid: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_sdf.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
